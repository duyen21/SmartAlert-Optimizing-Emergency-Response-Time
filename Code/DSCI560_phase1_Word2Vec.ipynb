{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install contractions\n","# !pip install transformers\n","!pip install --upgrade gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwZikK4cQXF1","outputId":"4c50c6a0-be42-457a-c3f2-f11e5b12ecae","executionInfo":{"status":"ok","timestamp":1682280971098,"user_tz":420,"elapsed":21416,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: contractions in /usr/local/lib/python3.9/dist-packages (0.1.73)\n","Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.9/dist-packages (from contractions) (0.0.24)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.9/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.9/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n"]}]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"C_IkzyS5Cxlf","executionInfo":{"status":"ok","timestamp":1682280971098,"user_tz":420,"elapsed":13,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"p2zQf03E4y1C","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba442eef-b006-49ee-b00f-08c5148a783a","executionInfo":{"status":"ok","timestamp":1682281063648,"user_tz":420,"elapsed":92562,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import pandas as pd\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","import contractions\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import GridSearchCV\n","\n","import gensim.downloader as api\n","wv = api.load('word2vec-google-news-300')\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","source":["# with open('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Duyen/data/ggvec.npy', 'wb') as f:\n","#     np.save(f,wv)\n","\n","# Save the model to a file\n","wv.save('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Duyen/data/gg_wv')"],"metadata":{"id":"7i-hYG3_CnmT","executionInfo":{"status":"ok","timestamp":1682284631284,"user_tz":420,"elapsed":16857,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Duyen/data/cleaned/train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Duyen/data/cleaned/test.csv')\n","df_val = pd.read_csv('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Duyen/data/cleaned/val.csv')\n"],"metadata":{"id":"lbyelqnCQZdB","executionInfo":{"status":"ok","timestamp":1682281101403,"user_tz":420,"elapsed":353,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_train"],"metadata":{"id":"gJfk4i6iRzt4","colab":{"base_uri":"https://localhost:8080/","height":468},"outputId":"7fd95f13-dd07-41d2-dfbb-a44e0551f68b","executionInfo":{"status":"ok","timestamp":1682281101625,"user_tz":420,"elapsed":237,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              tweet_text     location  \\\n","0      donbradshawntv marshallampsuk came assistance ...       Canada   \n","1      red cross distributes fo mcmurray wildfire eva...       Canada   \n","2      interesting insights shifting communications l...       Canada   \n","3      globeandmail oil sands producers helping worke...       Canada   \n","4      ottawa match red cross donations fo mcmurray w...       Canada   \n","...                                                  ...          ...   \n","31181  https co mzh h uqh nepal cloud burst death tol...        Earth   \n","31182  wear uniform days year rain shine flood draugh...   Hopes Peak   \n","31183      flash flood town dad still wants water plants   Boston, MA   \n","31184  brahmaputra water level recedes assam flood to...        India   \n","31185  timguinee maybe people live hurricane prone ar...  Atlanta, GA   \n","\n","            type  target                   datetime  year        date  \\\n","0       wildfire       0        2016-05-06 16:54:00  2016  2016-05-06   \n","1       wildfire       1        2016-05-30 17:30:57  2016  2016-05-30   \n","2       wildfire       0        2016-04-30 23:18:34  2016  2016-04-30   \n","3       wildfire       0        2016-05-30 08:00:05  2016  2016-05-30   \n","4       wildfire       0        2016-05-06 21:06:11  2016  2016-05-06   \n","...          ...     ...                        ...   ...         ...   \n","31181  hurricane       0  2017-08-14 03:32:29+00:00  2017  2017-08-14   \n","31182  hurricane       0  2017-08-11 09:27:36+00:00  2017  2017-08-11   \n","31183      flood       0  2017-08-02 20:44:29+00:00  2017  2017-08-02   \n","31184      flood       0  2017-08-19 03:20:57+00:00  2017  2017-08-19   \n","31185  hurricane       0  2017-08-25 21:23:55+00:00  2017  2017-08-25   \n","\n","           time  \n","0      16:54:00  \n","1      17:30:57  \n","2      23:18:34  \n","3      08:00:05  \n","4      21:06:11  \n","...         ...  \n","31181  03:32:29  \n","31182  09:27:36  \n","31183  20:44:29  \n","31184  03:20:57  \n","31185  21:23:55  \n","\n","[31186 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-c2d02153-15ff-4f3e-82db-464d318a61c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>location</th>\n","      <th>type</th>\n","      <th>target</th>\n","      <th>datetime</th>\n","      <th>year</th>\n","      <th>date</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>donbradshawntv marshallampsuk came assistance ...</td>\n","      <td>Canada</td>\n","      <td>wildfire</td>\n","      <td>0</td>\n","      <td>2016-05-06 16:54:00</td>\n","      <td>2016</td>\n","      <td>2016-05-06</td>\n","      <td>16:54:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>red cross distributes fo mcmurray wildfire eva...</td>\n","      <td>Canada</td>\n","      <td>wildfire</td>\n","      <td>1</td>\n","      <td>2016-05-30 17:30:57</td>\n","      <td>2016</td>\n","      <td>2016-05-30</td>\n","      <td>17:30:57</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>interesting insights shifting communications l...</td>\n","      <td>Canada</td>\n","      <td>wildfire</td>\n","      <td>0</td>\n","      <td>2016-04-30 23:18:34</td>\n","      <td>2016</td>\n","      <td>2016-04-30</td>\n","      <td>23:18:34</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>globeandmail oil sands producers helping worke...</td>\n","      <td>Canada</td>\n","      <td>wildfire</td>\n","      <td>0</td>\n","      <td>2016-05-30 08:00:05</td>\n","      <td>2016</td>\n","      <td>2016-05-30</td>\n","      <td>08:00:05</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ottawa match red cross donations fo mcmurray w...</td>\n","      <td>Canada</td>\n","      <td>wildfire</td>\n","      <td>0</td>\n","      <td>2016-05-06 21:06:11</td>\n","      <td>2016</td>\n","      <td>2016-05-06</td>\n","      <td>21:06:11</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>31181</th>\n","      <td>https co mzh h uqh nepal cloud burst death tol...</td>\n","      <td>Earth</td>\n","      <td>hurricane</td>\n","      <td>0</td>\n","      <td>2017-08-14 03:32:29+00:00</td>\n","      <td>2017</td>\n","      <td>2017-08-14</td>\n","      <td>03:32:29</td>\n","    </tr>\n","    <tr>\n","      <th>31182</th>\n","      <td>wear uniform days year rain shine flood draugh...</td>\n","      <td>Hopes Peak</td>\n","      <td>hurricane</td>\n","      <td>0</td>\n","      <td>2017-08-11 09:27:36+00:00</td>\n","      <td>2017</td>\n","      <td>2017-08-11</td>\n","      <td>09:27:36</td>\n","    </tr>\n","    <tr>\n","      <th>31183</th>\n","      <td>flash flood town dad still wants water plants</td>\n","      <td>Boston, MA</td>\n","      <td>flood</td>\n","      <td>0</td>\n","      <td>2017-08-02 20:44:29+00:00</td>\n","      <td>2017</td>\n","      <td>2017-08-02</td>\n","      <td>20:44:29</td>\n","    </tr>\n","    <tr>\n","      <th>31184</th>\n","      <td>brahmaputra water level recedes assam flood to...</td>\n","      <td>India</td>\n","      <td>flood</td>\n","      <td>0</td>\n","      <td>2017-08-19 03:20:57+00:00</td>\n","      <td>2017</td>\n","      <td>2017-08-19</td>\n","      <td>03:20:57</td>\n","    </tr>\n","    <tr>\n","      <th>31185</th>\n","      <td>timguinee maybe people live hurricane prone ar...</td>\n","      <td>Atlanta, GA</td>\n","      <td>hurricane</td>\n","      <td>0</td>\n","      <td>2017-08-25 21:23:55+00:00</td>\n","      <td>2017</td>\n","      <td>2017-08-25</td>\n","      <td>21:23:55</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>31186 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2d02153-15ff-4f3e-82db-464d318a61c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c2d02153-15ff-4f3e-82db-464d318a61c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c2d02153-15ff-4f3e-82db-464d318a61c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df_train['text_split'] = df_train['tweet_text'].str.split()\n","df_train = df_train.dropna()\n","\n","df_test['text_split'] = df_test['tweet_text'].str.split()\n","df_test = df_test.dropna()\n","\n","df_val['text_split'] = df_val['tweet_text'].str.split()\n","df_val = df_val.dropna()"],"metadata":{"id":"yYr8xUh7naze","executionInfo":{"status":"ok","timestamp":1682281102308,"user_tz":420,"elapsed":686,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df_train.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TG4tH5W5otog","outputId":"407334ca-d4b3-4dae-e72b-f11eeebe0748","executionInfo":{"status":"ok","timestamp":1682281102717,"user_tz":420,"elapsed":415,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tweet_text    0\n","location      0\n","type          0\n","target        0\n","datetime      0\n","year          0\n","date          0\n","time          0\n","text_split    0\n","dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Create an empty list to store the mean vectors\n","mean_vectors = []\n","\n","# Iterate over each row of the DataFrame\n","for index, row in df_train.iterrows():\n","    # Convert each list of words into a numpy array of word embeddings\n","    word_embeddings = []\n","    for word in row['text_split']:\n","        try:\n","            word_embeddings.append(wv[word])\n","        except KeyError:\n","            pass\n","    if word_embeddings == []:\n","      mean_vector = np.array(wv['unk'])\n","    else:\n","      # Calculate the mean vector of the word embeddings along the first axis\n","      mean_vector = np.array(np.mean(np.array(word_embeddings), axis=0))\n","    # Append the mean vector to the list\n","    mean_vectors.append(mean_vector)"],"metadata":{"id":"Zjai50XU4pMg","executionInfo":{"status":"ok","timestamp":1682281108055,"user_tz":420,"elapsed":5343,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Create an empty list to store the mean vectors test set\n","mean_vectors_test = []\n","\n","# Iterate over each row of the DataFrame\n","for index, row in df_test.iterrows():\n","    # Convert each list of words into a numpy array of word embeddings\n","    word_embeddings_test = []\n","    for word in row['text_split']:\n","        try:\n","            word_embeddings_test.append(wv[word])\n","        except KeyError:\n","            pass\n","    if word_embeddings_test == []:\n","      mean_vector_test = np.array(wv['unk'])\n","    else:\n","      # Calculate the mean vector of the word embeddings along the first axis\n","      mean_vector_test = np.array(np.mean(np.array(word_embeddings_test), axis=0))\n","    # Append the mean vector to the list\n","    mean_vectors_test.append(mean_vector_test)"],"metadata":{"id":"pL_S93W9EetY","executionInfo":{"status":"ok","timestamp":1682281109175,"user_tz":420,"elapsed":1138,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Create an empty list to store the mean vectors test set\n","mean_vectors_val = []\n","\n","# Iterate over each row of the DataFrame\n","for index, row in df_val.iterrows():\n","    # Convert each list of words into a numpy array of word embeddings\n","    word_embeddings_val = []\n","    for word in row['text_split']:\n","        try:\n","            word_embeddings_val.append(wv[word])\n","        except KeyError:\n","            pass\n","    if word_embeddings_val == []:\n","      word_embeddings_val = np.array(wv['unk'])\n","    else:\n","      # Calculate the mean vector of the word embeddings along the first axis\n","      mean_vector_val = np.array(np.mean(np.array(word_embeddings_val), axis=0))\n","    # Append the mean vector to the list\n","    mean_vectors_val.append(mean_vectors_val)"],"metadata":{"id":"A_LMxW9QLAeg","executionInfo":{"status":"ok","timestamp":1682281109818,"user_tz":420,"elapsed":646,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["X_train = mean_vectors\n","y_train = df_train['target']\n","X_test = mean_vectors_test\n","y_test = df_test['target']\n","\n","# Use SMOTE to oversample the minority class\n","smote = SMOTE(random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"],"metadata":{"id":"x75dLapdjU_8","executionInfo":{"status":"ok","timestamp":1682281112579,"user_tz":420,"elapsed":2764,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#Random Forest\n","clf = RandomForestClassifier(n_estimators=100, random_state=42)\n","clf.fit(X_train_resampled, y_train_resampled)\n","\n","# Make predictions on validation set\n","y_pred_rf = clf.predict(X_test)\n","\n","precision_rf = precision_score(y_test, y_pred_rf)\n","recall_rf = recall_score(y_test, y_pred_rf)\n","f1_rf = f1_score(y_test, y_pred_rf)\n","roc_auc_rf = roc_auc_score(y_test, y_pred_rf)"],"metadata":{"id":"8-3vfd0AEJvz","executionInfo":{"status":"ok","timestamp":1682281249755,"user_tz":420,"elapsed":137182,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# SVM\n","clf_svm = make_pipeline(LinearSVC(random_state=0, tol=1e-5))\n","clf_svm.fit(X_train_resampled, y_train_resampled)\n","\n","y_pred_svm = clf_svm.predict(X_test)\n","\n","precision_svm = precision_score(y_test, y_pred_svm)\n","recall_svm = recall_score(y_test, y_pred_svm)\n","f1_svm = f1_score(y_test, y_pred_svm)\n","roc_auc_svm = roc_auc_score(y_test, y_pred_svm)"],"metadata":{"id":"sMw2Ame3VM9E","executionInfo":{"status":"ok","timestamp":1682281283682,"user_tz":420,"elapsed":33952,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import SimpleRNN, GRU, LSTM, Dense, Activation\n","\n","# convert input data from list to numpy array\n","X_train_resampled = np.array(X_train_resampled)\n","y_train_resampled = np.array(y_train_resampled)\n","X_test = np.array(X_test)\n","\n","model = Sequential()\n","model.add(Dense(100, activation='relu', input_dim=X_train_resampled.shape[1]))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train_resampled, y_train_resampled, epochs=20, batch_size=32, validation_split=0.1)\n","\n","# Evaluate the model\n","y_pred_fnn = model.predict(X_test)\n","# y_pred_fnn = np.argmax(y_pred_fnn, axis=1)"],"metadata":{"id":"NS1VZUhV6TPk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee278f1a-30a2-47f4-e8de-4591514a4447","executionInfo":{"status":"ok","timestamp":1682281375808,"user_tz":420,"elapsed":92145,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1274/1274 [==============================] - 5s 3ms/step - loss: 0.3722 - accuracy: 0.8375 - val_loss: 0.3647 - val_accuracy: 0.8446\n","Epoch 2/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.3075 - accuracy: 0.8691 - val_loss: 0.2667 - val_accuracy: 0.9035\n","Epoch 3/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.2795 - accuracy: 0.8840 - val_loss: 0.1993 - val_accuracy: 0.9362\n","Epoch 4/20\n","1274/1274 [==============================] - 11s 9ms/step - loss: 0.2564 - accuracy: 0.8944 - val_loss: 0.2037 - val_accuracy: 0.9298\n","Epoch 5/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.2374 - accuracy: 0.9049 - val_loss: 0.1428 - val_accuracy: 0.9576\n","Epoch 6/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.2192 - accuracy: 0.9131 - val_loss: 0.1925 - val_accuracy: 0.9316\n","Epoch 7/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.2038 - accuracy: 0.9199 - val_loss: 0.2298 - val_accuracy: 0.9130\n","Epoch 8/20\n","1274/1274 [==============================] - 5s 4ms/step - loss: 0.1885 - accuracy: 0.9254 - val_loss: 0.1380 - val_accuracy: 0.9578\n","Epoch 9/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.1754 - accuracy: 0.9317 - val_loss: 0.1656 - val_accuracy: 0.9406\n","Epoch 10/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.1632 - accuracy: 0.9377 - val_loss: 0.1001 - val_accuracy: 0.9706\n","Epoch 11/20\n","1274/1274 [==============================] - 4s 3ms/step - loss: 0.1498 - accuracy: 0.9434 - val_loss: 0.1031 - val_accuracy: 0.9709\n","Epoch 12/20\n","1274/1274 [==============================] - 5s 4ms/step - loss: 0.1383 - accuracy: 0.9463 - val_loss: 0.1136 - val_accuracy: 0.9618\n","Epoch 13/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.1282 - accuracy: 0.9513 - val_loss: 0.1028 - val_accuracy: 0.9664\n","Epoch 14/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.1165 - accuracy: 0.9566 - val_loss: 0.1138 - val_accuracy: 0.9603\n","Epoch 15/20\n","1274/1274 [==============================] - 4s 3ms/step - loss: 0.1078 - accuracy: 0.9603 - val_loss: 0.1385 - val_accuracy: 0.9452\n","Epoch 16/20\n","1274/1274 [==============================] - 4s 3ms/step - loss: 0.0974 - accuracy: 0.9647 - val_loss: 0.0853 - val_accuracy: 0.9728\n","Epoch 17/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.0911 - accuracy: 0.9668 - val_loss: 0.0534 - val_accuracy: 0.9837\n","Epoch 18/20\n","1274/1274 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.9706 - val_loss: 0.0333 - val_accuracy: 0.9925\n","Epoch 19/20\n","1274/1274 [==============================] - 4s 3ms/step - loss: 0.0761 - accuracy: 0.9731 - val_loss: 0.0474 - val_accuracy: 0.9872\n","Epoch 20/20\n","1274/1274 [==============================] - 4s 3ms/step - loss: 0.0683 - accuracy: 0.9753 - val_loss: 0.0277 - val_accuracy: 0.9936\n","276/276 [==============================] - 0s 1ms/step\n"]}]},{"cell_type":"code","source":["y_pred_binary = (y_pred_fnn > 0.5).astype(int)\n","# y_pred_binary"],"metadata":{"id":"Bje3tvvLiELQ","executionInfo":{"status":"ok","timestamp":1682281375809,"user_tz":420,"elapsed":28,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["precision_fnn = precision_score(y_test, y_pred_binary)\n","recall_fnn = recall_score(y_test, y_pred_binary)\n","f1_fnn = f1_score(y_test, y_pred_binary)\n","roc_auc_fnn = roc_auc_score(y_test, y_pred_binary)"],"metadata":{"id":"nQqy-zJ9hDnt","executionInfo":{"status":"ok","timestamp":1682281375810,"user_tz":420,"elapsed":12,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["data = {'Model': ['Random Forest', 'Support Vector Machine', 'Feedforward Neural Network'],\n","        'Precision': [precision_rf, precision_svm, precision_fnn],\n","        'Recall': [recall_rf, recall_svm, recall_fnn],\n","        'F1': [f1_rf, f1_svm, f1_fnn],\n","        'ROC-AUC': [roc_auc_rf, roc_auc_svm, roc_auc_fnn]}\n","\n","df = pd.DataFrame(data)\n","df = df.set_index('Model')\n","\n","print(df)\n"],"metadata":{"id":"M72kuCcwiq4H","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa02a023-8f77-471f-c48b-96cbe022491e","executionInfo":{"status":"ok","timestamp":1682281375811,"user_tz":420,"elapsed":13,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["                            Precision    Recall        F1   ROC-AUC\n","Model                                                              \n","Random Forest                0.730233  0.647156  0.686189  0.778145\n","Support Vector Machine       0.652018  0.825639  0.728629  0.829081\n","Feedforward Neural Network   0.713690  0.775763  0.743433  0.828740\n"]}]},{"cell_type":"code","source":["import pickle\n","\n","# Assuming that you have a trained model called \"model\"\n","# Save the model to a file called \"model.pkl\"\n","with open('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Models/svm_classification.pkl', 'wb') as f:\n","    pickle.dump(clf_svm, f)\n","\n","# Load the saved model from the file\n","with open('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Models/svm_classification.pkl', 'rb') as f:\n","    model_svm = pickle.load(f)\n","\n","# Assuming that you have a trained model called \"model\"\n","# Save the model to a file called \"model.pkl\"\n","with open('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Models/rf_classification.pkl', 'wb') as f:\n","    pickle.dump(clf, f)\n","\n","# Load the saved model from the file\n","with open('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Models/rf_classification.pkl', 'rb') as f:\n","    model_rf = pickle.load(f)\n","\n","# Assuming that you have a trained model called \"model\"\n","# Save the model to a file called \"model.pkl\"\n","with open('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Models/fnn_classification.pkl', 'wb') as f:\n","    pickle.dump(model, f)\n","\n","# Load the saved model from the file\n","with open('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Models/fnn_classification.pkl', 'rb') as f:\n","    model_fnn = pickle.load(f)    "],"metadata":{"id":"A-9VyoiFkWYn","executionInfo":{"status":"ok","timestamp":1682281417832,"user_tz":420,"elapsed":1472,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["new_df1 = pd.read_csv('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Apify Uploads/dataset.csv')\n","new_df1 = new_df1[['created_at','full_text']]\n","new_df2 = pd.read_csv('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Apify Uploads/dataset (1).csv')\n","new_df2 = new_df2[['created_at','full_text']]\n","new_df3 = pd.read_csv('/content/drive/MyDrive/DSCI560/TeamProject-DSCI560/Apify Uploads/dataset_twitter-latest-scraper_2023-04-20_17-11-15-498.csv')\n","new_df3 = new_df3[['created_at','full_text']]\n","new_df = pd.concat([new_df1, new_df2, new_df3], axis=0)"],"metadata":{"id":"mTjdONToHM7L","executionInfo":{"status":"ok","timestamp":1682282941557,"user_tz":420,"elapsed":517,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# new_df.to_csv('/content/drive/MyDrive/DSCI560/concatenated_df.csv')"],"metadata":{"id":"Ga5wuuYhTwnQ","executionInfo":{"status":"ok","timestamp":1682281377242,"user_tz":420,"elapsed":15,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["stopwords_english = stopwords.words('english')\n","# convert to lower case\n","new_df['full_text'] = new_df['full_text'].str.lower()\n","\n","# remove the HTML and URLs from the reviews (ref: https://stackoverflow.com/questions/45999415/removing-html-tags-in-pandas)\n","new_df['full_text'] = new_df['full_text'].str.replace(r'<[^<>]*>', '', regex=True)\n","\n","# remove non-alphabetical characters and punctuations from all tweets.\n","# print(string.punctuation)\n","new_df['full_text'] = new_df['full_text'].str.replace('[^a-zA-Z]', ' ').replace('[{}]'.format(string.punctuation), '')\n","\n","# remove extra spaces from all reviews.\n","new_df['full_text'] = new_df['full_text'].str.strip()\n","\n","# perform contractions on the reviews by using the package contractions (ref: https://www.dataquest.io/blog/how-to-clean-and-prepare-your-data-for-analysis/).\n","# new_df['full_text'] = new_df['full_text'].astype(str).apply(lambda x: contractions.fix(x))\n","\n","#remove the stop words (ref: https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe)\n","new_df['full_text'] = new_df['full_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_english)]))\n","\n","new_df['text_split'] = new_df['full_text'].str.split()\n","new_df = new_df.dropna()"],"metadata":{"id":"VTM_7pDYHf22","executionInfo":{"status":"ok","timestamp":1682282944016,"user_tz":420,"elapsed":153,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["new_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KhsefmpK3kMo","executionInfo":{"status":"ok","timestamp":1682282945957,"user_tz":420,"elapsed":196,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}},"outputId":"7bfd2b87-adef-46f5-9009-f11701008ee8"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(250, 3)"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["# Create an empty list to store the mean vectors\n","mean_vectors_infer = []\n","\n","# Iterate over each row of the DataFrame\n","for index, row in new_df.iterrows():\n","    # Convert each list of words into a numpy array of word embeddings\n","    word_embeddings_infer = []\n","    for word in row['text_split']:\n","        try:\n","            word_embeddings_infer.append(wv[word])\n","        except KeyError:\n","            pass\n","    if word_embeddings_infer == []:\n","      mean_vector_infer = np.array(wv['unk'])\n","    else:\n","      # Calculate the mean vector of the word embeddings along the first axis\n","      mean_vector_infer = np.array(np.mean(np.array(word_embeddings_infer), axis=0))\n","    # Append the mean vector to the list\n","    mean_vectors_infer.append(mean_vector_infer)"],"metadata":{"id":"2NnXdoZQRh98","executionInfo":{"status":"ok","timestamp":1682282950266,"user_tz":420,"elapsed":258,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["X_test_infer = mean_vectors_infer\n","\n","# Use the loaded model to make predictions on the new dataset\n","predictions_svm = model_svm.predict(X_test_infer)\n","predictions_rf = model_rf.predict(X_test_infer)\n","# predictions_fnn = model_fnn.predict(X_test)"],"metadata":{"id":"d0LHM_Z-GzBI","executionInfo":{"status":"ok","timestamp":1682282985612,"user_tz":420,"elapsed":185,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["X_test_infer_ = np.array(X_test_infer)"],"metadata":{"id":"QE3Hk68QR4Nl","executionInfo":{"status":"ok","timestamp":1682283022343,"user_tz":420,"elapsed":144,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["predictions_fnn = model_fnn.predict(X_test_infer_)\n","predictions_fnn = (predictions_fnn > 0.5).astype(int)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfjAXvLS0ioZ","executionInfo":{"status":"ok","timestamp":1682283023750,"user_tz":420,"elapsed":584,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}},"outputId":"e3564be2-eadc-4dfc-fc38-f9d6a73aa9b7"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["8/8 [==============================] - 0s 3ms/step\n"]}]},{"cell_type":"code","source":["# predictions_fnn"],"metadata":{"id":"M3eewAsezHHQ","executionInfo":{"status":"ok","timestamp":1682283406901,"user_tz":420,"elapsed":361,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["flattened_arr = predictions_fnn.ravel()\n","\n","\n","tweet_dict1 = {'tweet_text': new_df['full_text'], 'label': predictions_svm}\n","tweet_dict2 = {'tweet_text': new_df['full_text'], 'label': predictions_rf}\n","tweet_dict3 = {'tweet_text': new_df['full_text'], 'label': flattened_arr}\n","\n","# Convert the dictionary to a pandas dataframe\n","tweet_df1 = pd.DataFrame(tweet_dict1)\n","tweet_df2 = pd.DataFrame(tweet_dict2)\n","tweet_df3 = pd.DataFrame(tweet_dict3)\n","\n","\n","tweet_df = pd.concat([tweet_df1, tweet_df2, tweet_df3], axis=0)\n","\n","# Filter the dataframe to only include tweets with a label of 1\n","disaster_df = tweet_df[tweet_df['label'] == 1].reset_index(drop=True)"],"metadata":{"id":"elNWcnh3SKr4","executionInfo":{"status":"ok","timestamp":1682283306752,"user_tz":420,"elapsed":155,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["disaster_df.drop_duplicates(subset=['tweet_text', 'label']).reset_index(drop=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Wl1GwIiczdQU","executionInfo":{"status":"ok","timestamp":1682283338349,"user_tz":420,"elapsed":10,"user":{"displayName":"Duyen Nguyen","userId":"10624257161405867732"}},"outputId":"2a946b7d-966f-45f1-9806-a4dc614f44e6"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           tweet_text  label\n","0   earthquake magnitudo samoa islands region minu...      1\n","1                                                          1\n","2   marcorubio cbsmiami notice floods useless gove...      1\n","3   sti spreading like wildfire flood victims evac...      1\n","4                mikehudema stop building flood zones      1\n","5                   mejenwalton dutchbros nicely done      1\n","6   salvalucania icardiyolog ilkertiano ultrasturk...      1\n","7   marquette county declares local state emergenc...      1\n","8   stillgray men dressing painting like women con...      1\n","9                                sorunun sorunu flood      1\n","10  bozkurtkutlubey kemalistsad bi ara flood mu ya...      1\n","11             anyone list voters need flood ethernet      1\n","12  whetstonesdp yvettehenson air raid sirens anym...      1\n","13                   drunkonsaturday alabama slam lol      1\n","14  grantstern know desantis could personally stop...      1\n","15                        tomhennessey need new flood      1\n","16  evacuation drill puerto vallarta highlights im...      1\n","17   coyjandreau thorburnthomas restorethesndyerverse      1\n","18  estimated million people threatened floods hap...      1\n","19  rockville new flood mitigation program reimbur...      1\n","20  ramprasad c relative us wanted rivian bought t...      1\n","21                                         earthquake      1\n","22  think know florida flooded last week seeded st...      1\n","23  recently michelangelo madonna della piet reloc...      1\n","24  earthquake information new event earthquake us...      1\n","25  bir ey hakk nda yarg da bulunmadan nce u soruy...      1\n","26                                maskofbun aight bet      1\n","27  integral part turkey heritage antakya orthodox...      1\n","28                         btexas mischief earthquake      1\n","29                earthquakes one morning actual fuck      1\n","30  mikehudema omg oh flood sorry geard never seen...      1\n","31  bennastaran kadar etkilesim aldin ki flood yap...      1\n","32  last uk earthquake wed apr location slattadale...      1\n","33  massive earthquake strike time predict magnitu...      1"],"text/html":["\n","  <div id=\"df-fcf2e62e-107a-4f82-8228-8cbb9795fa3f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>earthquake magnitudo samoa islands region minu...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td></td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>marcorubio cbsmiami notice floods useless gove...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sti spreading like wildfire flood victims evac...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>mikehudema stop building flood zones</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>mejenwalton dutchbros nicely done</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>salvalucania icardiyolog ilkertiano ultrasturk...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>marquette county declares local state emergenc...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>stillgray men dressing painting like women con...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>sorunun sorunu flood</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>bozkurtkutlubey kemalistsad bi ara flood mu ya...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>anyone list voters need flood ethernet</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>whetstonesdp yvettehenson air raid sirens anym...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>drunkonsaturday alabama slam lol</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>grantstern know desantis could personally stop...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>tomhennessey need new flood</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>evacuation drill puerto vallarta highlights im...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>coyjandreau thorburnthomas restorethesndyerverse</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>estimated million people threatened floods hap...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>rockville new flood mitigation program reimbur...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>ramprasad c relative us wanted rivian bought t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>earthquake</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>think know florida flooded last week seeded st...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>recently michelangelo madonna della piet reloc...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>earthquake information new event earthquake us...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>bir ey hakk nda yarg da bulunmadan nce u soruy...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>maskofbun aight bet</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>integral part turkey heritage antakya orthodox...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>btexas mischief earthquake</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>earthquakes one morning actual fuck</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>mikehudema omg oh flood sorry geard never seen...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>bennastaran kadar etkilesim aldin ki flood yap...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>last uk earthquake wed apr location slattadale...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>massive earthquake strike time predict magnitu...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcf2e62e-107a-4f82-8228-8cbb9795fa3f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fcf2e62e-107a-4f82-8228-8cbb9795fa3f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fcf2e62e-107a-4f82-8228-8cbb9795fa3f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":[],"metadata":{"id":"U3ldxssB60qW"},"execution_count":null,"outputs":[]}]}